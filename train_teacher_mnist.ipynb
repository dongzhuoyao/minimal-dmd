{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DMD2 Teacher Training - MNIST\n",
        "\n",
        "This notebook trains a teacher diffusion model on MNIST that will be used for DMD2 distillation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision tqdm -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model definition\n",
        "def get_sigmas_karras(n, sigma_min=0.002, sigma_max=80.0, rho=7.0):\n",
        "    \"\"\"Generate Karras noise schedule\"\"\"\n",
        "    ramp = torch.linspace(0, 1, n)\n",
        "    min_inv_rho = sigma_min ** (1 / rho)\n",
        "    max_inv_rho = sigma_max ** (1 / rho)\n",
        "    sigmas = (max_inv_rho + ramp * (min_inv_rho - max_inv_rho)) ** rho\n",
        "    return sigmas\n",
        "\n",
        "\n",
        "class TimeEmbedding(nn.Module):\n",
        "    \"\"\"Sinusoidal time embedding\"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = np.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = time[:, None] * emb[None, :]\n",
        "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    \"\"\"Residual block with time conditioning\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, out_channels)\n",
        "        )\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.GroupNorm(8, in_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.GroupNorm(8, out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "        )\n",
        "        self.res_conv = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb):\n",
        "        h = self.block1(x)\n",
        "        time_emb = self.time_mlp(time_emb)\n",
        "        h = h + time_emb[:, :, None, None]\n",
        "        h = self.block2(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"Self-attention block\"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.norm = nn.GroupNorm(8, channels)\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, 1)\n",
        "        self.proj = nn.Conv2d(channels, channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.norm(x)\n",
        "        qkv = self.qkv(h)\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "        \n",
        "        # Reshape for attention\n",
        "        q = q.view(B, C, H * W).permute(0, 2, 1)\n",
        "        k = k.view(B, C, H * W)\n",
        "        v = v.view(B, C, H * W).permute(0, 2, 1)\n",
        "        \n",
        "        # Attention\n",
        "        scale = (C // 1) ** -0.5\n",
        "        attn = torch.softmax(q @ k * scale, dim=-1)\n",
        "        h = (attn @ v).permute(0, 2, 1).view(B, C, H, W)\n",
        "        \n",
        "        return x + self.proj(h)\n",
        "\n",
        "\n",
        "class SimpleUNet(nn.Module):\n",
        "    \"\"\"Simple UNet for MNIST\"\"\"\n",
        "    def __init__(self, img_channels=1, label_dim=10, time_emb_dim=128):\n",
        "        super().__init__()\n",
        "        self.time_emb_dim = time_emb_dim\n",
        "        self.time_embed = TimeEmbedding(time_emb_dim)\n",
        "        \n",
        "        # Label embedding\n",
        "        self.label_embed = nn.Embedding(label_dim, time_emb_dim)\n",
        "        \n",
        "        # Downsampling\n",
        "        self.conv_in = nn.Conv2d(img_channels, 64, 3, padding=1)\n",
        "        self.down1 = ResBlock(64, 128, time_emb_dim)\n",
        "        self.down2 = ResBlock(128, 256, time_emb_dim)\n",
        "        self.down3 = ResBlock(256, 512, time_emb_dim)\n",
        "        \n",
        "        # Middle\n",
        "        self.mid_block1 = ResBlock(512, 512, time_emb_dim)\n",
        "        self.mid_attn = AttentionBlock(512)\n",
        "        self.mid_block2 = ResBlock(512, 512, time_emb_dim)\n",
        "        \n",
        "        # Upsampling\n",
        "        self.up1 = ResBlock(512 + 256, 256, time_emb_dim)\n",
        "        self.up2 = ResBlock(256 + 128, 128, time_emb_dim)\n",
        "        self.up3 = ResBlock(128 + 64, 64, time_emb_dim)\n",
        "        \n",
        "        # Output\n",
        "        self.norm_out = nn.GroupNorm(8, 64)\n",
        "        self.conv_out = nn.Conv2d(64, img_channels, 3, padding=1)\n",
        "        \n",
        "    def forward(self, x, sigma, label, return_bottleneck=False):\n",
        "        # Handle sigma\n",
        "        if isinstance(sigma, (int, float)) or (isinstance(sigma, torch.Tensor) and sigma.dim() == 0):\n",
        "            sigma = torch.full((x.shape[0],), float(sigma), device=x.device)\n",
        "        elif sigma.dim() > 1:\n",
        "            sigma = sigma.squeeze()\n",
        "        \n",
        "        # Handle label\n",
        "        if label.dim() > 1:\n",
        "            label = label.argmax(dim=1)\n",
        "        \n",
        "        # Time embedding from sigma\n",
        "        time_emb = self.time_embed(sigma)\n",
        "        label_emb = self.label_embed(label)\n",
        "        time_emb = time_emb + label_emb\n",
        "        \n",
        "        # Downsampling\n",
        "        h1 = self.conv_in(x)\n",
        "        h2 = self.down1(h1, time_emb)\n",
        "        h2_down = nn.functional.avg_pool2d(h2, 2)\n",
        "        h3 = self.down2(h2_down, time_emb)\n",
        "        h3_down = nn.functional.avg_pool2d(h3, 2)\n",
        "        h4 = self.down3(h3_down, time_emb)\n",
        "        h4_down = nn.functional.avg_pool2d(h4, 2)\n",
        "        \n",
        "        # Middle\n",
        "        h = self.mid_block1(h4_down, time_emb)\n",
        "        h = self.mid_attn(h)\n",
        "        h = self.mid_block2(h, time_emb)\n",
        "        \n",
        "        if return_bottleneck:\n",
        "            return h\n",
        "        \n",
        "        # Upsampling\n",
        "        h = nn.functional.interpolate(h, size=h3.shape[2:], mode='nearest')\n",
        "        h = torch.cat([h, h3], dim=1)\n",
        "        h = self.up1(h, time_emb)\n",
        "        \n",
        "        h = nn.functional.interpolate(h, size=h2.shape[2:], mode='nearest')\n",
        "        h = torch.cat([h, h2], dim=1)\n",
        "        h = self.up2(h, time_emb)\n",
        "        \n",
        "        h = nn.functional.interpolate(h, size=h1.shape[2:], mode='nearest')\n",
        "        h = torch.cat([h, h1], dim=1)\n",
        "        h = self.up3(h, time_emb)\n",
        "        \n",
        "        # Output\n",
        "        h = self.norm_out(h)\n",
        "        h = nn.functional.silu(h)\n",
        "        out = self.conv_out(h)\n",
        "        \n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "config = {\n",
        "    'data_dir': './data',\n",
        "    'output_dir': './checkpoints/teacher',\n",
        "    'batch_size': 128,\n",
        "    'lr': 1e-4,\n",
        "    'num_epochs': 100,\n",
        "    'num_train_timesteps': 1000,\n",
        "    'sigma_min': 0.002,\n",
        "    'sigma_max': 80.0,\n",
        "    'sigma_data': 0.5,\n",
        "    'rho': 7.0,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'save_every': 5000,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(config['output_dir'], exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load MNIST Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=config['data_dir'],\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Dataset loaded: {len(train_dataset)} training samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model = SimpleUNet(img_channels=1, label_dim=10).to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=0.01)\n",
        "\n",
        "# Karras noise schedule\n",
        "sigmas = get_sigmas_karras(\n",
        "    config['num_train_timesteps'],\n",
        "    sigma_min=config['sigma_min'],\n",
        "    sigma_max=config['sigma_max'],\n",
        "    rho=config['rho']\n",
        ")\n",
        "sigmas = sigmas.to(device)\n",
        "\n",
        "sigma_data = config['sigma_data']\n",
        "\n",
        "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    for batch_idx, (images, labels) in enumerate(pbar):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Sample random timesteps\n",
        "        timesteps = torch.randint(\n",
        "            0, config['num_train_timesteps'],\n",
        "            (images.shape[0],),\n",
        "            device=device,\n",
        "            dtype=torch.long\n",
        "        )\n",
        "        timestep_sigma = sigmas[timesteps]\n",
        "        \n",
        "        # Add noise\n",
        "        noise = torch.randn_like(images)\n",
        "        noisy_images = images + timestep_sigma.reshape(-1, 1, 1, 1) * noise\n",
        "        \n",
        "        # Predict x0\n",
        "        pred_x0 = model(noisy_images, timestep_sigma, labels)\n",
        "        \n",
        "        # Karras loss weighting\n",
        "        snrs = timestep_sigma ** -2\n",
        "        weights = snrs + 1.0 / (sigma_data ** 2)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = torch.mean(\n",
        "            weights.reshape(-1, 1, 1, 1) * (pred_x0 - images) ** 2\n",
        "        )\n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['max_grad_norm'])\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        global_step += 1\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\"loss\": loss.item(), \"avg_loss\": epoch_loss / (batch_idx + 1)})\n",
        "        \n",
        "        # Save checkpoint periodically\n",
        "        if global_step % config['save_every'] == 0:\n",
        "            checkpoint_path = os.path.join(\n",
        "                config['output_dir'],\n",
        "                f\"teacher_checkpoint_step_{global_step}.pt\"\n",
        "            )\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'step': global_step,\n",
        "                'epoch': epoch,\n",
        "            }, checkpoint_path)\n",
        "            print(f\"\\nSaved checkpoint to {checkpoint_path}\")\n",
        "\n",
        "# Save final checkpoint\n",
        "final_checkpoint_path = os.path.join(config['output_dir'], \"teacher_final.pt\")\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'step': global_step,\n",
        "    'epoch': config['num_epochs'],\n",
        "}, final_checkpoint_path)\n",
        "print(f\"\\nSaved final checkpoint to {final_checkpoint_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
